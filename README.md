```
ΕΠ08 Αναγνώριση Προτύπων – Μηχανική Μάθηση
```
# 1 η Εργασία: Τα βασικά της μηχανικής μάθησης

Τύπος εργασίας: **_Ατομική_**

Ημερομηνία παράδοσης: **_Τρίτη 31 /0 3 /202 2 , 23:_**

Τρόπος παράδοσης: **_Αποκλειστικά μέσω του eclass_**

Σύνολο βαθμών: **100** (10% του τελικού βαθμού του μαθήματος)

```
Σε αυτή, τη πρώτη, εργασία του μαθήματος Αναγνώρισης Προτύπων – Μηχανική Μάθηση
καλείστε να απαντήσετε ερωτήματα που αφορούν στο βασικό μαθηματικό υπόβαθρο των
μεθοδολογιών μηχανικής μάθησης. Η εργασία είναι ατομική και αποτελείται από τρία
ερωτήματα. Συνιστάται ιδιαίτερα, να αφιερώσετε χρόνο ώστε να κατανοήσετε τον
θεμελιώδη λογισμό πίσω από τα ερωτήματα της εργασίας και να αποφύγετε την αναζήτηση
έτοιμων λύσεων στο διαδίκτυο. Αν ωστόσο συμβουλευτείτε ή/και χρησιμοποιήσετε
οποιοδήποτε υλικό ή/και κώδικα που είναι διαθέσιμος στο διαδίκτυο, πρέπει να αναφέρεται
σωστά τη πηγή ή/και το σύνδεσμο στην ιστοσελίδα που αντλήσατε πληροφορίες. Σε κάθε
περίπτωση, η αντιγραφή τμήματος ή του συνόλου της εργασίας δεν είναι αποδεκτή και στη
περίπτωση που διαπιστωθεί αντιγραφή θα μηδενιστούν στο μάθημα όλα τα εμπλεκόμενα
μέρη.
```
```
Θα πρέπει να υποβάλετε ένα μόνο αρχείο Notebook IPython (Jupiter notebook) μέσω του
εργαλείου εργασίες του eclass , ακολουθώντας την εξής σύβαση ονομασίας για το αρχείο
σας: Επώνυμο_ΑριθμόςΜητρώου.ipynb
```
```
Tόσο ο κώδικας Python όσο και οι απαντήσεις σας στις αναλυτικές/αριθμητικές ερωτήσεις
πρέπει να είναι ενσωματωμένα στο ίδιο IPython notebook. Οι μαθηματικές πράξεις μπορούν
να ενσωματωθούν στο IPython notebook είτε χρησιμοποιώντας LaTeX σημειογραφία είτε ως
εικόνες (π.χ. φωτογραφία χειρόγραφου). Μπορείτε να χρησιμοποιήσετε κελιά επικεφαλίδας
για να οργανώσετε περαιτέρω το έγγραφό σας.
```
```
Σημαντικό: Το IPython notebook που θα παραδώσετε θα πρέπει βεβαιωθείτε ότι ανοίγει και
να εκτελείται στο google colab.
```
```
[Ερώτημα 1: Πράξεις με Διανύσματα και Πίνακες] ( 10 βαθμοί)
```
```
Η εξοικείωση με το λογισμό διανυσμάτων και πινάκων είναι απαραίτητη για την κατανόηση
και την υλοποίηση αλγορίθμων μηχανικής μάθησης. Για το σκοπό αυτό, καλείστε να
απαντήσετε στα παρακάτω ερωτήματα.
```
```
Χρησιμοποιώντας το πακέτο random της NumPy να δημιουργήσετε:
i) Δύο τυχαίους πίνακες ακέραιων αριθμών και.
ii) Δύο τυχαία διανύσματα ακέραιων αριθμών και
```
```
1.1 Να υπολογίσετε το εσωτερικό γινόμενο των διανυσμάτων και , δηλαδή
1.2 Να υπολογίσετε το γινόμενο πίνακα-διανύσματος
1.3 Να υπολογίσετε το γινόμενο πινάκων
```
### X ∈ℤ^3 ×^4 Y ∈ℤ^4 ×^3

```
a ∈ℤ^4 b ∈ℤ^4
```
## a b a T b

```
Xa ∈ℤ^3
XY ∈ℤ^3 ×^3
```

1.4 Να υπολογίσετε την Ευκλείδεια νόρμα (l 2 - norm) του διανύσματος
Στις παραπάνω ερωτήσεις καλείστε να εκτελέστε τους υπολογισμούς αναλυτικά βήμα προς
βήμα με το χέρι, παραθέτοντας όλα τα ενδιάμεσα βήματα και να επιβεβαιώστε τα
αποτελέσματα με τη χρήση της NumPy.

**Σημαντικό:** Για να είναι συνεπή τα τυχαία αποτελέσματα, να ορίστε το seed στη γεννήτρια
τυχαίων αριθμών ως τα τελευταία 4 ψηφία του αριθμού μητρώου σας

**[Ερώτημα 2: Υπολογισμός παραγώγων]** ( 20 βαθμοί)

Ένα πολύ ευρύ σύνολο αλγορίθμων μηχανικής μάθησης απαιτούν την επίλυση κατάλληλων
προβλημάτων βελτιστοποίησης στα οποία ο υπολογισμός παραγώγων συναρτήσεων
πολλών μεταβλητών είναι κεντρικής σημασίας. Για την εξοικείωσή σας με τον υπολογισμό
παραγώγων και την αναλυτική επίλυση προβλημάτων βελτιστοποίησης καλείστε να
απαντήσετε στα παρακάτω ερωτήματα. Αυτό το ερώτημα αποτελεί καλή ευκαιρία για να
ξεκινήσετε να χρησιμοποιείται το The Matrix Cookbook στη πράξη.

The Matrix Cookbook είναι διαθέσιμο στο σύνδεσμο:
https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf

2.1 Έστω , μια συνάρτηση d μεταβλητών, με συμμετρικό πίνακα (δηλ.
) διάστασης d x d, και. Να υπολογίσετε αναλυτικά βήμα προς βήμα με το χέρι,
την παράγωγο της ως προς το διάνυσμα παραθέτωντας όλα τα ενδιάμεσα βήματα.

Υπενθιμίζεται ότι η παράγωγος μιας συνάρτησης , ως προς το διάνυσμα
είναι:

2.2 Έστω **Α** , **Β** , **Χ** πίνακες πραγματικών αριθμών διάστασης d x d με τάξη (rank) ίση με d. Nα
βρείτε, αναλυτικά και σε κλειστή μορφή (closed form solution) το ολικό ελάχιστο του
παρακάτω προβλήματος βελτιστοποίησης:

Να εξηγήσετε με λεπτομέρεια όλη τη διαδικασία σκέψης που θα ακολουθήσετε και να
παραθέσετε όλα τα ενδιάμεσα βήματα των πράξεων.

**[Ερώτημα 3 : Gradient descent]** ( 70 βαθμοί)

Ο αλγόριθμος gradient descent είναι η πιο διαδεδομένη μέθοδος βελτιστοποίησης στη
μηχανική μάθηση. Σε αυτό το ερώτημα καλείστε να υλοποιήσετε σε Python τον αλγόριθμο
gradient descent για την ελαχιστοποίηση συναρτήσεων δύο μεταβλητών.

# a

```
f ( x )= x TA x + b T x A
```
**A** = **A** _T_ **b** ∈ℝ _d
f_ ( **x** ) **x** ∈ℝ _d_

```
f :ℝ d →ℝ∇ f ( x ) x ∈ℝ d
```
```
∇ f ( x )=
```
```
∂ f ( x )
∂ x 1
⋮
∂ f ( x )
∂ xd
```
```
∈ℝ d
```
```
min
X
```
```
∥ A − XB ∥^2 F
```

Θεωρήστε τις παρακάτω συναρτήσεις:

Nα υλοποιήσετε σε Python και να εκτελέστε τον αλγόριθμο gradient descent για κάθε
συνάρτηση.

Να αρχικοποιήσετε τις μεταβλητές με μηδέν. Πρώτα, τρέξτε με ένα σταθερό ποσοστό
εκμάθησης (learning rate) ίσο με 0 .5. Να εκτελέστε Τ=10 επαναλήψεις και αναφέρετε την
τιμή της συνάρτησης στο τέλος κάθε βήματος (επανάληψης). Χρησιμοποιώντας τη matplotlib
να σχεδιάσετε γραφήματα (ένα για κάθε συνάρτηση) που να απεικονίζουν την τιμή της
συνάρτησης (κάθετος άξονας) ως συνάρτηση των επαναλήψεων (οριζόντιος άξονας).

Στη συνέχεια, να επαναλάβετε τη διαδικασία για διαφορετικές τιμές του learning rate και
του πλήθους επαναλήψεων (Τ) και αναφέρετε τα αποτελέσματά σας με τη μορφή
γραφημάτων όπως στο παραπάνω σκέλος του ερωτήματος. Πόσες επαναλήψεις χρειάζεται
ο αλγόριθμος για να συγκλίνει σε στάσιμο σημείο για διαφορετικές τιμές του learning rate
για κάθε συνάρτηση; Τι συμβαίνει για μεγάλες τιμές του learning rate; Τι συμβαίνει για
μικρές τιμές του learning rate; Τι συμβαίνει εαν χρησιμοποιήσετε διαφορετικές τιμές
αρχικοποίησης;

```
f 1 ([ x 1 , x 2 ] T )= f 1 ( x 1 , x 2 )=( x 1 − 2 )^2 +( x 2 − 3 )^2
```
_f_ 2 ([ _x_ 1 , _x_ 2 ] _T_ )= _f_ 2 ( _x_ 1 , _x_ 2 )=( 1 −( _x_ 2 − 3 ))^2 + (^20) (( _x_ 1 + 3 )−( _x_ 2 − 3 )^2 )
2


